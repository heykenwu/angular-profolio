<div
  class="banner-innerpage"
  style="background-image: url(assets/images/project/epoll_banner.jpeg)"
>
  <div class="container">
    <!-- Row  -->
    <div class="row justify-content-center">
      <!-- Column -->
      <div class="col-lg-9 col-md-6 no-trans align-self-center text-center">
        <h1 class="title">Comparison between epoll and select server</h1>
      </div>
      <!-- Column -->
    </div>
    </div>
</div>
<!-- ============================================================== -->
<!-- Feature 22  -->
<!-- ============================================================== -->
<div class="header_outer">
    <h2 class="header_t md-display-1">
        <strong >
            In this project, we are going to compare the scalability and performance of the select and epoll-based client server implementations.
        </strong>
        </h2>
</div>
<div class="container">
    <h1 class="md-display-3"><strong>Apporach</strong></h1>
    <h3 class="md-headline">
        The client server implementation will be a simple echo-reply server. The main functionality of the client is to send the server with a message, and read the reply from the server, the process will continue several times. As for the servers, the main functionality is to process the client's echo request and reply back with the same echo message. Two versions of server are implemented - an ​ epoll ​ version and a ​ select ​ version. Both versions will have similar architecture in terms of implementation.
    </h3>
    <h3 class="md-headline">
        Each client will also maintain a record of how many requests it made to the server, the amount of data sent to the server, and the amount of time it took for the server to respond. The server will maintain a list of all connected clients (host names) and store the list together with the number of requests generated by each client and the amount of data transferred to each client.
    </h3>
    <h3 class="md-headline">
        The figure below shows an overview of the workflow:
    </h3>
    <div class="design_img_container">
        <img class="design" src="assets/images/project/epoll_workfow.PNG">
        </div>
        <div class="caption">
        <em>figure 1 workflow</em>
    </div>
    <h1 class="md-display-3"><strong>Source code</strong></h1>
    <h3 class="md-headline">
        The project source code can be found <a href="">here</a>.
    </h3>
    <h1 class="md-display-3"><strong>State Diagram</strong></h1>
    <h3 class="md-headline">
       The figure below is the epoll server state diagram:
    </h3>
    <div class="design_img_container">
        <img class="design" src="assets/images/project/epoll_st.PNG">
        </div>
        <div class="caption">
        <em>figure 2 epoll server state diagram</em>
    </div>
    <h3 class="md-headline">
        The figure below is the select server state diagram:
     </h3>
    <div class="design_img_container">
        <img class="design" src="assets/images/project/epoll_st1.PNG">
        </div>
        <div class="caption">
        <em>figure 3 select server state diagram</em>
    </div>
    <h3 class="md-headline">
        The figure below is the client state diagram:
     </h3>
    <div class="design_img_container">
        <img class="design" src="assets/images/project/epoll_st2.PNG">
        </div>
        <div class="caption">
        <em>figure 4 client state diagram</em>
    </div>
    <h1 class="md-display-3"><strong>Usage</strong></h1>
    <div class="usage">
    <h3 class="md-headline">
        Name <br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;client.c<br>
        Option<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-h (--host)&nbsp;&nbsp;hostname<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-p (--port)&nbsp;&nbsp;server listening port<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-m (--message)&nbsp;echo message<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-c (--count)&nbsp;&nbsp;number of echo request to send<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-d (--delay)&nbsp;&nbsp;delay between request (nsec, max 1 sec)
     </h3>
     </div>
     <div class="usage">
     <h3 class="md-headline">
        Name <br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;server.c (select)<br>
        Option<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-p (--p)&nbsp;&nbsp;listening port
     </h3>
     </div>
     <div>
    <h3 class="md-headline">
        Name <br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;server.c (epoll)<br>
        Option<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-p (--port)&nbsp;&nbsp;listening port<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-m (--max-core)&nbsp;number of worker thread to scale accept
        </h3>
        </div>
        <h1 class="md-display-3"><strong>How to run</strong></h1>
        <h3 class="md-headline">
            Client<br>
On the client machine, cd to the “client” folder. Fill in the server info in the Makefile, and run<br>
<strong>$ make all</strong><br>
If the server is running, the client should display some results in console.
        </h3>
        <h3 class="md-headline">
            Server (select)<br>
            On the server machine, cd to the “select” folder, Fill the value for the macro “PORT” in the Makefile, and run<br>
            <strong>$ make all</strong><br>
            The console should display message indicating server is running
        </h3>
        <h3 class="md-headline">
            Server (epoll)<br>
            On the server machine, cd to the “epoll” folder, Fill the value for the macro “PORT” and “MAX_CORES” in the Makefile, and run<br>
            <strong>$ make all</strong><br>
            The console should display message indicating server is running.
        </h3>
        <h1 class="md-display-3"><strong>Testing</strong></h1>
        <h3 class="md-headline">
            The idea is to keep adding workload to the server until the server shows a significant degradation in performance.
             We will increase the workload by adding more clients, more sent requests and bigger echo messages.
              At the end of the testing (both ​ epoll ​ and ​ select server), the result of each of the test cases will be grouped together,and plotted into a line graph.
        </h3>
        <h3 class="md-headline">
            The Makefiles in each of the “select” and “epoll” folder contains both test scripts test-a and test-b.
        </h3>
        <h3 class="md-headline">
            <strong>Test Script</strong><br>
            <strong>test-a</strong><br>
            Spawns a fixed number of clients per interval for a fixed number of times. The client spawn from this test will send string data to the server periodically.<br>
            <strong>test-b</strong><br>
            Keep on adding clients per interval indefinitely. The client spawn from this test will send string data to the server periodically.
        </h3>
        <h3 class="md-headline">
            The command for running the test is <strong>$make test-a</strong>​ and <strong>$make test-b</strong>.
        </h3>
        <h3 class="md-headline">
           <strong>Case 1</strong><br>
           In this case, we try to determine the maximum active socket the server can handle in one session. We use the ​ test-b ​ test script to keep adding clients indefinitely until there’s a significant degradation in performance on the server side. Each spawn client will send an echo request to the server and wait for a reply, this process will continue for enough time until the performance on server side drop.
        </h3>
        <h3 class="md-headline">
            <strong>Testing params</strong>
        </h3>
        <ul>
            <li>
              <h3 class="md-headline">
                20000 echo request (10000 each on two client machines)
            </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    10000 nsec delay in between each echo request (not including the response time from previous request)
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    0.002 sec client spawn delay
                </h3>
            </li>
          </ul>
          <h3 class="md-headline">
            <strong>Monitoring tool </strong>: Wireshark
        </h3>
        <h3 class="md-headline">
            <strong>select server statistic</strong><br>
            The hard limit for the select() server is 1024, so we will not test it. The number is confirmed by looking at the source code for the ​ FD_SET ​ type, which consists of an integer list of size 32. 
            (one bit represents one socket, i.e there's 32*16 = ​<strong>1024</strong>​ socket max)
        </h3>
        <h3 class="md-headline">
            <strong>epoll server statistic</strong>
        </h3>
        <div class="design_img_container">
            <img class="design" src="assets/images/project/epoll_wireshark_conversation_1.PNG">
            </div>
            <div class="caption">
            <em>figure 5 Wireshark conversations on epoll server</em>
        </div>
        <div class="design_img_container">
            <img class="design" src="assets/images/project/epoll_wireshark_conversation_2.PNG">
            </div>
            <div class="caption">
            <em>figure 6 Wireshark I/O graph on epoll server</em>
        </div>
        <h3 class="md-headline">
            <strong>Case 2</strong><br>
            In this case, we are testing the server performance when requests are sent infrequently during an active connection. We use ​ test-a ​ to spawn a fixed number of clients, and keep all the connections active for around 3 minutes.
        </h3>
        <h3 class="md-headline">
            <strong>Testing params</strong>
        </h3>
        <ul>
            <li>
              <h3 class="md-headline">
                6 spawn cycle, 256 spawn per cycle = 1024 clients in total
            </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    0.02 sec client spawn delay
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    100000 request per client (will not process all if 3 minutes hit)
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    10 msec delay between each request (not including response time from previous request)
                </h3>
            </li>
          </ul>
          <h3 class="md-headline">
            <strong>Monitoring tool </strong>: Wireshark
        </h3>
        <h3 class="md-headline">
            <strong>Result</strong>
        </h3>
        <div class="design_img_container">
            <img class="design" src="assets/images/project/epoll_io_1.PNG">
            </div>
            <div class="caption">
            <em>figure 7 Wireshark I/O graph on select server</em>
        </div>
            <div class="design_img_container">
                <img class="design" src="assets/images/project/epoll_io_2.PNG">
                </div>
                <div class="caption">
                <em>figure 8 Wireshark I/O graph on epoll server</em>
        </div>
        <h3 class="md-headline">
            <strong>Case 3</strong><br>
            In this case, we are testing the server performance when requests are sent frequently during an active connection. We use ​ test-a ​ to spawn a fixed number of clients, and keep all the connections active for around 10 sec.
        </h3>
        <h3 class="md-headline">
            <strong>Testing params</strong>
        </h3>
        <ul>
            <li>
                <h3 class="md-headline">
                    1 spawn cycle, 256 spawn per cycle = 256 clients in total
            </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    0.02 sec client spawn delay
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    100000 request per client (will not process all if 3 minutes hit)
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    0.1 msec delay between each request (not including response time from previous request)
                </h3>
            </li>
            </ul>
            <h3 class="md-headline">
            <strong>Monitoring tool </strong>: Wireshark
        </h3>
        <h3 class="md-headline">
            <strong>Result</strong>
        </h3>
        <div class="design_img_container">
            <img class="design" src="assets/images/project/epoll_io_3.PNG">
            </div>
            <div class="caption">
            <em>figure 9 Wireshark I/O graph on select server</em>
            </div>
            <div class="design_img_container">
                <img class="design" src="assets/images/project/epoll_io_4.PNG">
                </div>
                <div class="caption">
                <em>figure 10 Wireshark I/O graph on epoll server</em>
        </div>
        <h3 class="md-headline">
            <strong>Case 4</strong><br>
            In this case, we are testing the server response performance when there's short live, intense traffic coming in. We use ​ test-b ​ to spawn clients indefinitely. Each client will keep the connection alive until they receive all pending replies from the server.
        </h3>
        <h3 class="md-headline">
            <strong>Testing params</strong>
        </h3>
        <ul>
            <li>
                <h3 class="md-headline">
                    Keep spawning clients until 300 spawn
            </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    0.01 sec client spawn delay
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    1 request per client
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    1 msec delay between each request (not including response time from previous request)
                </h3>
            </li>
            </ul>
            <h3 class="md-headline">
            <strong>Monitoring tool </strong>: response time record kept on client side
        </h3>
        <h3 class="md-headline">
            <strong>Result</strong>
        </h3>
        <div class="design_img_container">
            <img class="design" src="assets/images/project/epoll_client_1.PNG">
            </div>
            <div class="caption">
            <em>figure 11 Respond time from select server (per client)</em>
            </div>
            <div class="design_img_container">
                <img class="design" src="assets/images/project/epoll_client_2.PNG">
                </div>
                <div class="caption">
                <em>figure 12 Respond time from epoll server  (per client)</em>
        </div>
        <h3 class="md-headline">
            <strong>Case 5</strong><br>
            In this case, we are testing the server response performance when there's short live, intense traffic coming in. We use ​ test-b ​ to spawn clients indefinitely. Each client will keep the connection alive until they receive ​ one​ reply from the server.
        </h3>
        <h3 class="md-headline">
            <strong>Testing params</strong>
        </h3>
        <ul>
            <li>
                <h3 class="md-headline">
                    Keep spawning clients until 300 spawn
            </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    0.01 sec client spawn delay
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    1000 request per client
                </h3>
            </li>
            <li>
                <h3 class="md-headline">
                    1 msec delay between each request (not including response time from previous request)
                </h3>
            </li>
            </ul>
            <h3 class="md-headline">
            <strong>Monitoring tool </strong>: response time record kept on client side
        </h3>
        <h3 class="md-headline">
            <strong>Result</strong>
        </h3>
        <div class="design_img_container">
            <img class="design" src="assets/images/project/epoll_client_3.PNG">
            </div>
            <div class="caption">
            <em>figure 11 Respond time from select server (per client)</em>
            </div>
            <div class="design_img_container">
                <img class="design" src="assets/images/project/epoll_client_4.PNG">
                </div>
                <div class="caption">
                <em>figure 12 Respond time from epoll server  (per client)</em>
        </div>
        <h1 class="md-display-3"><strong>Analysis</strong></h1>
        <h3 class="md-headline">
            <strong>Case 1</strong><br>
            The hard limit on the select server is ​ 1024 ​ active sockets in one session. As for the epoll server, according to the wireshark conversation, we recorded a total of roughly 20000 active socket connections in one session. We could have kept the test longer, and the number will go higher. However, the wireshark IO graph on the epoll server shows that the number of incoming packets dropped when the active socket count hits ​ 20000 ​ mark. The drop happened because the server was not able to reply back to the client as quickly as before, i.e the response time increased. The client will only send one request when the previous request is answered.
        </h3>
        <h3 class="md-headline">
            <strong>Case 2</strong><br>
            The condition we made for this case is that data is sent infrequently while the connection is alive. The IO graph on select server shows an average of 6500 packets/s. As for the epoll server, the IO graph shows an average of roughly 6000 packets/s. One thing to note is that the incoming requests for the select server are comparably consistent than the epoll server. This indicates that the selected server has a fairly consistent response rate. The epoll server has a more inconsistent response rate.
        </h3>
        <h3 class="md-headline">
            <strong>Case 3</strong><br>
            The condition we made for this case is that data is sent more frequently than case 2, while the connection is alive. The IO graph on select server shows an average of 115000 packets/s. As for the epoll server, the IO graph shows an average of roughly 109000 packets/s. As we can see, the performance gap between select and epoll close in as the frequency of request increases.
        </h3>
        <h3 class="md-headline">
            <strong>Case 4</strong><br>
            The condition we made for this case is that connections are short live. The response time for the select server is roughly 9 sec in total (average of 0.009 sec per request), the epoll is roughly 15 sec (average of 0.015 sec per request). We will compare this data with the result.
        </h3>
        <h3 class="md-headline">
            <strong>Case 5</strong><br>
            The condition we made for this case is the same as case 4, except that this time the client will close the connection after receiving one only (even more short live than connections in case 4). The result shows that the response time for the select server is roughly 0.673 millisecond, the epoll server has a response time of roughly 0.403 millisecond. This time the epoll server seems to have a better performance than the select server.
        </h3>
        <h1 class="md-display-3"><strong>Explain</strong></h1>
        <h3 class="md-headline">
            The select server uses level trigger, while the epoll server uses edge trigger. The main difference is the event trigger mechanism. Level trigger will keep on notifying the event status on a socket as long as the status is readable (this could occur anywhere in the allocated time splice). Edge triggers will only notify once when the status on a socket changes (only occur during the beginning of time splice).
            </h3>
        <h3 class="md-headline">
            So does that mean epoll is more efficient than select? The test result in test case 2, 3 and 4 says otherwise. The results show that the select server has an overall higher response rate than the epoll server. This is because, each time, if there’s data from a client ready for ready, the select server will loop through all existing clients to see if there's data available. So if a data comes in from another client while the select server is looping through the list, there’s a good chance it will read it as well. In the case of an epoll server, it will only read on the socket that is ready for read, and that socket only.
            </h3>
        <h3 class="md-headline">
            The epoll server has some advantages over the select server as well. In case 1, it's evident to say that epoll can monitor why more sockets than select server. The result shows that select could monitor up to 1024 only, while the epoll can monitor 20000 sockets or more. Moreover, In case 5, the result shows that the epoll server has roughly 60% higher response rate than the select server. This happens because of the edge trigger implementation. To run edge trigger, the socket would have to be unblocking. If there’s a new connection request, the kernel will notify the server program (assuming the epoll_wait was called prior to the new connection). The behavior of epoll_wait requires the program to accept new connections until there’s no new connection in the queue list. If a new connection comes in while the server is accepting a connection, it will pick up the new connection as well. This explains why the epoll server has better performance than select server in case 5.
            </h3>
       <h1 class="md-display-3"><strong>Conclusion</strong></h1>  
       <h3 class="md-headline">
        Epoll is useful when implementing a server that deals with massive number of short live connections in a short period of time. This is because the server prioritizes accepting new connections.
       </h3>
       <h3 class="md-headline">
        Select is useful when implementing a server that handles moderate amounts, long live connection with frequent request. This is because the server prioritizes reading datas from the client. 
    </h3>
    <h3 class="md-headline">
        This conclusion is made based on the fact that either version of server scale out the read or accept operation. It will be difficult to implement scalability in select server because of the level trigger mechanism (wakes up all blocking select calls). This is not the case for epoll because of the default behavior of edge trigger (only wake up one blocking epoll_wait call). So if the epoll scale out the blocking operation, it is possible that the epoll server will yield better performance than select server on all aspects.
    </h3>
</div>